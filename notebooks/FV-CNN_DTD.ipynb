{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "from texture import fisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describable Textures Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1880, 1880, 1880)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtd_dir = '/home/ross/Dropbox/benchmark/dtd'\n",
    "img_dir = dtd_dir+'/images/'\n",
    "\n",
    "# just use the first split (of 10) for now\n",
    "train_reader = csv.reader(open(dtd_dir+'/labels/train1.txt'))\n",
    "train_list = [row[0] for row in train_reader]\n",
    "\n",
    "val_reader = csv.reader(open(dtd_dir+'/labels/val1.txt'))\n",
    "val_list = [row[0] for row in val_reader]\n",
    "\n",
    "test_reader = csv.reader(open(dtd_dir+'/labels/test1.txt'))\n",
    "test_list = [row[0] for row in test_reader]\n",
    "\n",
    "len(train_list), len(val_list), len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,\n",
       " ['banded',\n",
       "  'blotchy',\n",
       "  'braided',\n",
       "  'bubbly',\n",
       "  'bumpy',\n",
       "  'chequered',\n",
       "  'cobwebbed',\n",
       "  'cracked',\n",
       "  'crosshatched',\n",
       "  'crystalline',\n",
       "  'dotted',\n",
       "  'fibrous',\n",
       "  'flecked',\n",
       "  'freckled',\n",
       "  'frilly',\n",
       "  'gauzy',\n",
       "  'grid',\n",
       "  'grooved',\n",
       "  'honeycombed',\n",
       "  'interlaced',\n",
       "  'knitted',\n",
       "  'lacelike',\n",
       "  'lined',\n",
       "  'marbled',\n",
       "  'matted',\n",
       "  'meshed',\n",
       "  'paisley',\n",
       "  'perforated',\n",
       "  'pitted',\n",
       "  'pleated',\n",
       "  'polka-dotted',\n",
       "  'porous',\n",
       "  'potholed',\n",
       "  'scaly',\n",
       "  'smeared',\n",
       "  'spiralled',\n",
       "  'sprinkled',\n",
       "  'stained',\n",
       "  'stratified',\n",
       "  'striped',\n",
       "  'studded',\n",
       "  'swirly',\n",
       "  'veined',\n",
       "  'waffled',\n",
       "  'woven',\n",
       "  'wrinkled',\n",
       "  'zigzagged'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = set([s.split('/')[0] for s in train_list])\n",
    "classes = sorted(list(classes))\n",
    "len(classes), classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_class(s):\n",
    "    return classes.index(s.split('/')[0])\n",
    "\n",
    "X_train = [io.imread(img_dir+f) for f in train_list]\n",
    "y_train = np.array([to_class(f) for f in train_list])\n",
    "\n",
    "X_val = [io.imread(img_dir+f) for f in val_list]\n",
    "y_val = np.array([to_class(f) for f in val_list])\n",
    "\n",
    "X_test = [io.imread(img_dir+f) for f in test_list]\n",
    "y_test = np.array([to_class(f) for f in test_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on train+val blindly, test on test\n",
    "X_train += X_val\n",
    "y_train = np.concatenate([y_train, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(480, 640, 3),\n",
       " (500, 497, 3),\n",
       " (400, 305, 3),\n",
       " (458, 610, 3),\n",
       " (640, 640, 3),\n",
       " (480, 640, 3),\n",
       " (490, 600, 3),\n",
       " (480, 480, 3),\n",
       " (432, 432, 3),\n",
       " (640, 640, 3)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in X_train[0:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FV-CNN with VGG16 ImageNet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, None, None, 512), 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv_vgg = fisher.FVCNN('vgg16', k=64)\n",
    "fv_vgg.cnn.output_shape, fv_vgg.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sample of) img_feats.shapes: [(300, 512), (225, 512), (108, 512), (266, 512), (400, 512)]\n",
      "all_feats.shape : (810376, 512)\n",
      "Fitting GMM with 64 clusters...\n",
      "Train SVC score:  0.999468085106383\n",
      "fit() elapsed:  1195.6614303588867\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "train_score = fv_vgg.fit(X_train, y_train)\n",
    "print('Train SVC score: ', train_score)\n",
    "print('fit() elapsed: ', time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6622340425531915"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Score\n",
    "fv_vgg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FV-CNN with VGG19 ImageNet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, None, None, 512), 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv_vggd = fisher.FVCNN('vgg19', k=64)\n",
    "fv_vggd.cnn.output_shape, fv_vggd.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sample of) img_feats.shapes: [(300, 512), (225, 512), (108, 512), (266, 512), (400, 512)]\n",
      "all_feats.shape : (810376, 512)\n",
      "Fitting GMM with 64 clusters...\n",
      "Train SVC score:  1.0\n",
      "fit() elapsed:  936.503992319107\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "train_score = fv_vggd.fit(X_train, y_train)\n",
    "print('Train SVC score: ', train_score)\n",
    "print('fit() elapsed: ', time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6664893617021277"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Score\n",
    "fv_vggd.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FV-CNN with ResNet50 ImageNet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, None, None, 2048), 2048)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv_res50 = fisher.FVCNN('resnet50', k=64)\n",
    "fv_res50.cnn.output_shape, fv_res50.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sample of) img_feats.shapes: [(300, 2048), (256, 2048), (130, 2048), (285, 2048), (400, 2048)]\n",
      "all_feats.shape : (884952, 2048)\n",
      "Fitting GMM with 64 clusters...\n",
      "Train SVC score:  1.0\n",
      "fit() elapsed:  3480.918876647949\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "train_score = fv_res50.fit(X_train, y_train)\n",
    "print('Train SVC score: ', train_score)\n",
    "print('fit() elapsed: ', time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7015957446808511"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Score\n",
    "fv_res50.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
